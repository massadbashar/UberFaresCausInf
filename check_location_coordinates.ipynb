{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naturalizer, 7, West 34th Street, Midtown South, Manhattan, New York County, City of New York, New York, 10001, United States\n"
     ]
    }
   ],
   "source": [
    "from geopy.geocoders import Nominatim\n",
    "\n",
    "# Initialize the geocoder\n",
    "geolocator = Nominatim(user_agent=\"nyc_uber_geocoder\")\n",
    "\n",
    "# Function to reverse geocode a single pair of coordinates\n",
    "def reverse_geocode(lat, lon):\n",
    "    location = geolocator.reverse((lat, lon), exactly_one=True)\n",
    "    return location.address if location else None\n",
    "\n",
    "latitude = 40.748817\n",
    "longitude = -73.985428\n",
    "location = reverse_geocode(latitude, longitude)\n",
    "print(location)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                     pickup_location  \\\n",
      "0  Naturalizer, 7, West 34th Street, Midtown Sout...   \n",
      "1  New York City Hall, 260, Broadway, Lower Manha...   \n",
      "\n",
      "                                    dropoff_location  \n",
      "0  38-20, Review Avenue, Blissville, Queens, Quee...  \n",
      "1  55, Wall Street, Whitehall, Manhattan Communit...  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Sample DataFrame\n",
    "data = {\n",
    "    'pickup_latitude': [40.748817, 40.712776],\n",
    "    'pickup_longitude': [-73.985428, -74.005974],\n",
    "    'dropoff_latitude': [40.730610, 40.706001],\n",
    "    'dropoff_longitude': [-73.935242, -74.008819],\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Apply reverse geocoding to each row\n",
    "df['pickup_location'] = df.apply(lambda row: reverse_geocode(row['pickup_latitude'], row['pickup_longitude']), axis=1)\n",
    "df['dropoff_location'] = df.apply(lambda row: reverse_geocode(row['dropoff_latitude'], row['dropoff_longitude']), axis=1)\n",
    "\n",
    "print(df[['pickup_location', 'dropoff_location']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    Naturalizer, 7, West 34th Street, Midtown Sout...\n",
       "1    New York City Hall, 260, Broadway, Lower Manha...\n",
       "Name: pickup_location, dtype: object"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['pickup_location']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>key</th>\n",
       "      <th>fare_amount</th>\n",
       "      <th>pickup_datetime</th>\n",
       "      <th>pickup_longitude</th>\n",
       "      <th>pickup_latitude</th>\n",
       "      <th>dropoff_longitude</th>\n",
       "      <th>dropoff_latitude</th>\n",
       "      <th>passenger_count</th>\n",
       "      <th>pickup_year</th>\n",
       "      <th>...</th>\n",
       "      <th>pickup_hour</th>\n",
       "      <th>pickup_minute</th>\n",
       "      <th>pickup_day_of_week</th>\n",
       "      <th>pickup_time_of_day</th>\n",
       "      <th>pickup_datetime_naive</th>\n",
       "      <th>SNOW</th>\n",
       "      <th>SNWD</th>\n",
       "      <th>TMAX</th>\n",
       "      <th>TMIN</th>\n",
       "      <th>is_holiday</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>55072468</td>\n",
       "      <td>2009-01-01 01:15:22.0000006</td>\n",
       "      <td>8.5</td>\n",
       "      <td>2009-01-01 01:15:22+00:00</td>\n",
       "      <td>-73.981918</td>\n",
       "      <td>40.779456</td>\n",
       "      <td>-73.957685</td>\n",
       "      <td>40.771043</td>\n",
       "      <td>2</td>\n",
       "      <td>2009</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2009-01-01</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-3.3</td>\n",
       "      <td>-9.4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>30813112</td>\n",
       "      <td>2009-01-01 01:59:17.0000001</td>\n",
       "      <td>13.0</td>\n",
       "      <td>2009-01-01 01:59:17+00:00</td>\n",
       "      <td>-73.983759</td>\n",
       "      <td>40.721389</td>\n",
       "      <td>-73.994833</td>\n",
       "      <td>40.687179</td>\n",
       "      <td>2</td>\n",
       "      <td>2009</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>59</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2009-01-01</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-3.3</td>\n",
       "      <td>-9.4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8688426</td>\n",
       "      <td>2009-01-01 02:05:03.0000003</td>\n",
       "      <td>10.6</td>\n",
       "      <td>2009-01-01 02:05:03+00:00</td>\n",
       "      <td>-73.956635</td>\n",
       "      <td>40.771254</td>\n",
       "      <td>-73.991528</td>\n",
       "      <td>40.749778</td>\n",
       "      <td>2</td>\n",
       "      <td>2009</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2009-01-01</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-3.3</td>\n",
       "      <td>-9.4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13190369</td>\n",
       "      <td>2009-01-01 02:09:13.0000003</td>\n",
       "      <td>12.2</td>\n",
       "      <td>2009-01-01 02:09:13+00:00</td>\n",
       "      <td>-73.984605</td>\n",
       "      <td>40.728020</td>\n",
       "      <td>-73.955746</td>\n",
       "      <td>40.776830</td>\n",
       "      <td>1</td>\n",
       "      <td>2009</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2009-01-01</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-3.3</td>\n",
       "      <td>-9.4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>45716268</td>\n",
       "      <td>2009-01-01 02:13:41.0000001</td>\n",
       "      <td>11.0</td>\n",
       "      <td>2009-01-01 02:13:41+00:00</td>\n",
       "      <td>-73.980127</td>\n",
       "      <td>40.737425</td>\n",
       "      <td>-74.009544</td>\n",
       "      <td>40.726025</td>\n",
       "      <td>4</td>\n",
       "      <td>2009</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>13</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2009-01-01</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-3.3</td>\n",
       "      <td>-9.4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                          key  fare_amount  \\\n",
       "0    55072468  2009-01-01 01:15:22.0000006          8.5   \n",
       "1    30813112  2009-01-01 01:59:17.0000001         13.0   \n",
       "2     8688426  2009-01-01 02:05:03.0000003         10.6   \n",
       "3    13190369  2009-01-01 02:09:13.0000003         12.2   \n",
       "4    45716268  2009-01-01 02:13:41.0000001         11.0   \n",
       "\n",
       "             pickup_datetime  pickup_longitude  pickup_latitude  \\\n",
       "0  2009-01-01 01:15:22+00:00        -73.981918        40.779456   \n",
       "1  2009-01-01 01:59:17+00:00        -73.983759        40.721389   \n",
       "2  2009-01-01 02:05:03+00:00        -73.956635        40.771254   \n",
       "3  2009-01-01 02:09:13+00:00        -73.984605        40.728020   \n",
       "4  2009-01-01 02:13:41+00:00        -73.980127        40.737425   \n",
       "\n",
       "   dropoff_longitude  dropoff_latitude  passenger_count  pickup_year  ...  \\\n",
       "0         -73.957685         40.771043                2         2009  ...   \n",
       "1         -73.994833         40.687179                2         2009  ...   \n",
       "2         -73.991528         40.749778                2         2009  ...   \n",
       "3         -73.955746         40.776830                1         2009  ...   \n",
       "4         -74.009544         40.726025                4         2009  ...   \n",
       "\n",
       "   pickup_hour  pickup_minute  pickup_day_of_week  pickup_time_of_day  \\\n",
       "0            1             15                   3                   0   \n",
       "1            1             59                   3                   0   \n",
       "2            2              5                   3                   0   \n",
       "3            2              9                   3                   0   \n",
       "4            2             13                   3                   0   \n",
       "\n",
       "   pickup_datetime_naive  SNOW SNWD  TMAX  TMIN  is_holiday  \n",
       "0             2009-01-01     0    0  -3.3  -9.4           1  \n",
       "1             2009-01-01     0    0  -3.3  -9.4           1  \n",
       "2             2009-01-01     0    0  -3.3  -9.4           1  \n",
       "3             2009-01-01     0    0  -3.3  -9.4           1  \n",
       "4             2009-01-01     0    0  -3.3  -9.4           1  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uber_data = pd.read_csv('uber_updated.csv')\n",
    "uber_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Manhattan\n",
      "Manhattan\n",
      "**************************************\n",
      "Manhattan\n",
      "Manhattan\n",
      "**************************************\n",
      "Manhattan\n",
      "Manhattan\n",
      "**************************************\n",
      "Manhattan\n",
      "Manhattan\n",
      "**************************************\n",
      "Manhattan\n",
      "Manhattan\n",
      "**************************************\n",
      "5.162086248397827\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "pickup_boroughs = {'Manhattan': 0, 'Queens': 0, 'Brooklyn': 0, 'Bronx': 0, 'Staten Island': 0}\n",
    "dropoff_boroughs = {'Manhattan': 0, 'Queens': 0, 'Brooklyn': 0, 'Bronx': 0, 'Staten Island': 0}\n",
    "\n",
    "\n",
    "t1 = time.time()\n",
    "# Iterate over the rows of the DataFrame\n",
    "for index, row in uber_data.tail(5).iterrows():\n",
    "\n",
    "    pickup_latitude = row['pickup_latitude']\n",
    "    pickup_longitude = row['pickup_longitude']\n",
    "    pickup_location = reverse_geocode(pickup_latitude, pickup_longitude)\n",
    "    pickup_location_list = location.split(', ')\n",
    "\n",
    "    dropoff_latitude = row['dropoff_latitude']\n",
    "    dropoff_longitude = row['dropoff_longitude']\n",
    "    dropoff_location = reverse_geocode(dropoff_latitude, dropoff_longitude)\n",
    "    dropoff_location_list = location.split(', ')\n",
    "\n",
    "    pickup_boroughs[pickup_location_list[-6]] += 1\n",
    "    dropoff_boroughs[dropoff_location_list[-6]] += 1 \n",
    "    \n",
    "    # print(location_list[-6])\n",
    "    # print(len(location_list))\n",
    "    print(pickup_location_list[-6])\n",
    "    print(dropoff_location_list[-6])\n",
    "    print('**************************************')\n",
    "t2 = time.time()\n",
    "print(t2-t1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickup_boroughs = {'Manhattan': 0, 'Queens': 0, 'Brooklyn': 0, 'Bronx': 0, 'Staten Island': 0}\n",
    "dropoff_boroughs = {'Manhattan': 0, 'Queens': 0, 'Brooklyn': 0, 'Bronx': 0, 'Staten Island': 0}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(199494, 22)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uber_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "DataSourceError",
     "evalue": "new-york-city-boroughs.geojson: No such file or directory",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mDataSourceError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 6\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mshapely\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mgeometry\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Point\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Step 1: Load borough boundaries\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# Assuming you have a GeoJSON file with the boundaries of NYC boroughs\u001b[39;00m\n\u001b[1;32m----> 6\u001b[0m boroughs \u001b[38;5;241m=\u001b[39m gpd\u001b[38;5;241m.\u001b[39mread_file(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnew-york-city-boroughs.geojson\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m# Step 2: Convert latitude and longitude to a Shapely Point\u001b[39;00m\n\u001b[0;32m      9\u001b[0m latitude \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m40.824312\u001b[39m  \u001b[38;5;66;03m# Example latitude\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Bashar\\anaconda3\\Lib\\site-packages\\geopandas\\io\\file.py:294\u001b[0m, in \u001b[0;36m_read_file\u001b[1;34m(filename, bbox, mask, columns, rows, engine, **kwargs)\u001b[0m\n\u001b[0;32m    291\u001b[0m             from_bytes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m    293\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m engine \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpyogrio\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m--> 294\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _read_file_pyogrio(\n\u001b[0;32m    295\u001b[0m         filename, bbox\u001b[38;5;241m=\u001b[39mbbox, mask\u001b[38;5;241m=\u001b[39mmask, columns\u001b[38;5;241m=\u001b[39mcolumns, rows\u001b[38;5;241m=\u001b[39mrows, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[0;32m    296\u001b[0m     )\n\u001b[0;32m    298\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m engine \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfiona\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    299\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m pd\u001b[38;5;241m.\u001b[39mapi\u001b[38;5;241m.\u001b[39mtypes\u001b[38;5;241m.\u001b[39mis_file_like(filename):\n",
      "File \u001b[1;32mc:\\Users\\Bashar\\anaconda3\\Lib\\site-packages\\geopandas\\io\\file.py:547\u001b[0m, in \u001b[0;36m_read_file_pyogrio\u001b[1;34m(path_or_bytes, bbox, mask, rows, **kwargs)\u001b[0m\n\u001b[0;32m    538\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m    539\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minclude_fields\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m and \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mignore_fields\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m keywords are deprecated, and \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    540\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwill be removed in a future release. You can use the \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcolumns\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m keyword \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    543\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m,\n\u001b[0;32m    544\u001b[0m     )\n\u001b[0;32m    545\u001b[0m     kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcolumns\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minclude_fields\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 547\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m pyogrio\u001b[38;5;241m.\u001b[39mread_dataframe(path_or_bytes, bbox\u001b[38;5;241m=\u001b[39mbbox, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Bashar\\anaconda3\\Lib\\site-packages\\pyogrio\\geopandas.py:261\u001b[0m, in \u001b[0;36mread_dataframe\u001b[1;34m(path_or_buffer, layer, encoding, columns, read_geometry, force_2d, skip_features, max_features, where, bbox, mask, fids, sql, sql_dialect, fid_as_index, use_arrow, on_invalid, arrow_to_pandas_kwargs, **kwargs)\u001b[0m\n\u001b[0;32m    256\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m use_arrow:\n\u001b[0;32m    257\u001b[0m     \u001b[38;5;66;03m# For arrow, datetimes are read as is.\u001b[39;00m\n\u001b[0;32m    258\u001b[0m     \u001b[38;5;66;03m# For numpy IO, datetimes are read as string values to preserve timezone info\u001b[39;00m\n\u001b[0;32m    259\u001b[0m     \u001b[38;5;66;03m# as numpy does not directly support timezones.\u001b[39;00m\n\u001b[0;32m    260\u001b[0m     kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdatetime_as_string\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m--> 261\u001b[0m result \u001b[38;5;241m=\u001b[39m read_func(\n\u001b[0;32m    262\u001b[0m     path_or_buffer,\n\u001b[0;32m    263\u001b[0m     layer\u001b[38;5;241m=\u001b[39mlayer,\n\u001b[0;32m    264\u001b[0m     encoding\u001b[38;5;241m=\u001b[39mencoding,\n\u001b[0;32m    265\u001b[0m     columns\u001b[38;5;241m=\u001b[39mcolumns,\n\u001b[0;32m    266\u001b[0m     read_geometry\u001b[38;5;241m=\u001b[39mread_geometry,\n\u001b[0;32m    267\u001b[0m     force_2d\u001b[38;5;241m=\u001b[39mgdal_force_2d,\n\u001b[0;32m    268\u001b[0m     skip_features\u001b[38;5;241m=\u001b[39mskip_features,\n\u001b[0;32m    269\u001b[0m     max_features\u001b[38;5;241m=\u001b[39mmax_features,\n\u001b[0;32m    270\u001b[0m     where\u001b[38;5;241m=\u001b[39mwhere,\n\u001b[0;32m    271\u001b[0m     bbox\u001b[38;5;241m=\u001b[39mbbox,\n\u001b[0;32m    272\u001b[0m     mask\u001b[38;5;241m=\u001b[39mmask,\n\u001b[0;32m    273\u001b[0m     fids\u001b[38;5;241m=\u001b[39mfids,\n\u001b[0;32m    274\u001b[0m     sql\u001b[38;5;241m=\u001b[39msql,\n\u001b[0;32m    275\u001b[0m     sql_dialect\u001b[38;5;241m=\u001b[39msql_dialect,\n\u001b[0;32m    276\u001b[0m     return_fids\u001b[38;5;241m=\u001b[39mfid_as_index,\n\u001b[0;32m    277\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m    278\u001b[0m )\n\u001b[0;32m    280\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m use_arrow:\n\u001b[0;32m    281\u001b[0m     meta, table \u001b[38;5;241m=\u001b[39m result\n",
      "File \u001b[1;32mc:\\Users\\Bashar\\anaconda3\\Lib\\site-packages\\pyogrio\\raw.py:196\u001b[0m, in \u001b[0;36mread\u001b[1;34m(path_or_buffer, layer, encoding, columns, read_geometry, force_2d, skip_features, max_features, where, bbox, mask, fids, sql, sql_dialect, return_fids, datetime_as_string, **kwargs)\u001b[0m\n\u001b[0;32m     56\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Read OGR data source into numpy arrays.\u001b[39;00m\n\u001b[0;32m     57\u001b[0m \n\u001b[0;32m     58\u001b[0m \u001b[38;5;124;03mIMPORTANT: non-linear geometry types (e.g., MultiSurface) are converted\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    191\u001b[0m \n\u001b[0;32m    192\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    194\u001b[0m dataset_kwargs \u001b[38;5;241m=\u001b[39m _preprocess_options_key_value(kwargs) \u001b[38;5;28;01mif\u001b[39;00m kwargs \u001b[38;5;28;01melse\u001b[39;00m {}\n\u001b[1;32m--> 196\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m ogr_read(\n\u001b[0;32m    197\u001b[0m     get_vsi_path_or_buffer(path_or_buffer),\n\u001b[0;32m    198\u001b[0m     layer\u001b[38;5;241m=\u001b[39mlayer,\n\u001b[0;32m    199\u001b[0m     encoding\u001b[38;5;241m=\u001b[39mencoding,\n\u001b[0;32m    200\u001b[0m     columns\u001b[38;5;241m=\u001b[39mcolumns,\n\u001b[0;32m    201\u001b[0m     read_geometry\u001b[38;5;241m=\u001b[39mread_geometry,\n\u001b[0;32m    202\u001b[0m     force_2d\u001b[38;5;241m=\u001b[39mforce_2d,\n\u001b[0;32m    203\u001b[0m     skip_features\u001b[38;5;241m=\u001b[39mskip_features,\n\u001b[0;32m    204\u001b[0m     max_features\u001b[38;5;241m=\u001b[39mmax_features \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;241m0\u001b[39m,\n\u001b[0;32m    205\u001b[0m     where\u001b[38;5;241m=\u001b[39mwhere,\n\u001b[0;32m    206\u001b[0m     bbox\u001b[38;5;241m=\u001b[39mbbox,\n\u001b[0;32m    207\u001b[0m     mask\u001b[38;5;241m=\u001b[39m_mask_to_wkb(mask),\n\u001b[0;32m    208\u001b[0m     fids\u001b[38;5;241m=\u001b[39mfids,\n\u001b[0;32m    209\u001b[0m     sql\u001b[38;5;241m=\u001b[39msql,\n\u001b[0;32m    210\u001b[0m     sql_dialect\u001b[38;5;241m=\u001b[39msql_dialect,\n\u001b[0;32m    211\u001b[0m     return_fids\u001b[38;5;241m=\u001b[39mreturn_fids,\n\u001b[0;32m    212\u001b[0m     dataset_kwargs\u001b[38;5;241m=\u001b[39mdataset_kwargs,\n\u001b[0;32m    213\u001b[0m     datetime_as_string\u001b[38;5;241m=\u001b[39mdatetime_as_string,\n\u001b[0;32m    214\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\Bashar\\anaconda3\\Lib\\site-packages\\pyogrio\\_io.pyx:1239\u001b[0m, in \u001b[0;36mpyogrio._io.ogr_read\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\Bashar\\anaconda3\\Lib\\site-packages\\pyogrio\\_io.pyx:219\u001b[0m, in \u001b[0;36mpyogrio._io.ogr_open\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mDataSourceError\u001b[0m: new-york-city-boroughs.geojson: No such file or directory"
     ]
    }
   ],
   "source": [
    "import geopandas as gpd\n",
    "from shapely.geometry import Point\n",
    "\n",
    "# Step 1: Load borough boundaries\n",
    "# Assuming you have a GeoJSON file with the boundaries of NYC boroughs\n",
    "boroughs = gpd.read_file('new-york-city-boroughs.geojson')\n",
    "\n",
    "# Step 2: Convert latitude and longitude to a Shapely Point\n",
    "latitude = 40.824312  # Example latitude\n",
    "longitude = -73.926457  # Example longitude\n",
    "location_point = Point(longitude, latitude)\n",
    "\n",
    "# Step 3: Check which borough contains the point\n",
    "borough_name = None\n",
    "for _, borough in boroughs.iterrows():\n",
    "    if borough['geometry'].contains(location_point):\n",
    "        borough_name = borough['name']  # Assuming the borough name is in a column called 'borough'\n",
    "        break\n",
    "\n",
    "# Step 4: Output the result\n",
    "if borough_name:\n",
    "    print(f\"The location is in the borough: {borough_name}\")\n",
    "else:\n",
    "    print(\"The location is not in any recognized borough.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import time\n",
    "# from borough_finder import BoroughFinder\n",
    "# # Initialize the BoroughFinder with the path to your GeoJSON file\n",
    "# geojson_path = 'new-york-city-boroughs.geojson'  # Adjust the path if necessary\n",
    "# finder = BoroughFinder(geojson_path)\n",
    "\n",
    "\n",
    "# pickup_boroughs = {'Manhattan': 0, 'Queens': 0, 'Brooklyn': 0, 'Bronx': 0, 'Staten Island': 0}\n",
    "# dropoff_boroughs = {'Manhattan': 0, 'Queens': 0, 'Brooklyn': 0, 'Bronx': 0, 'Staten Island': 0}\n",
    "\n",
    "# errors = 0\n",
    "# counter = 0\n",
    "\n",
    "# t1 = time.time()\n",
    "# # Iterate over the rows of the DataFrame\n",
    "# for index, row in uber_data.iterrows():\n",
    "#     counter += 1\n",
    "#     pickup_latitude = row['pickup_latitude']\n",
    "#     pickup_longitude = row['pickup_longitude']\n",
    "#     # pickup_location = reverse_geocode(pickup_latitude, pickup_longitude)\n",
    "#     # pickup_location_list = location.split(', ')\n",
    "\n",
    "#     pickup_borough = finder.find_borough(pickup_longitude, pickup_latitude)\n",
    "\n",
    "#     dropoff_latitude = row['dropoff_latitude']\n",
    "#     dropoff_longitude = row['dropoff_longitude']\n",
    "#     # dropoff_location = reverse_geocode(dropoff_latitude, dropoff_longitude)\n",
    "#     # dropoff_location_list = location.split(', ')\n",
    "\n",
    "#     dropoff_borough = finder.find_borough(dropoff_longitude, dropoff_latitude)\n",
    "\n",
    "#     try:\n",
    "#         pickup_boroughs[pickup_borough] += 1\n",
    "#         dropoff_boroughs[pickup_borough] += 1\n",
    "#     except:\n",
    "#         errors += 1\n",
    "#         print(f'Error with pickup: {pickup_borough} and dropoff: {dropoff_borough}')\n",
    "#         print(f'Current count: {errors} out of {counter}')\n",
    "\n",
    "    \n",
    "#     # print(location_list[-6])\n",
    "#     # print(len(location_list))\n",
    "#     # print(pickup_location_list[-6])\n",
    "#     # print(dropoff_location_list[-6])\n",
    "#     # print('**************************************')\n",
    "# t2 = time.time()\n",
    "# print(t2-t1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Manhattan': 0, 'Queens': 0, 'Brooklyn': 0, 'Bronx': 0, 'Staten Island': 0}\n",
      "{'Manhattan': 0, 'Queens': 0, 'Brooklyn': 0, 'Bronx': 0, 'Staten Island': 0}\n"
     ]
    }
   ],
   "source": [
    "print(pickup_boroughs)\n",
    "print(dropoff_boroughs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pickup: ('Upper West Side', 'Manhattan')\n",
      "Dropoff: ('Lenox Hill', 'Manhattan')\n",
      "**************************************\n",
      "Pickup: ('Lower East Side', 'Manhattan')\n",
      "Dropoff: ('Cobble Hill', 'Brooklyn')\n",
      "**************************************\n",
      "Pickup: ('Lenox Hill', 'Manhattan')\n",
      "Dropoff: ('Chelsea', 'Manhattan')\n",
      "**************************************\n",
      "Pickup: ('Manhattan Community Board 3', 'Manhattan')\n",
      "Dropoff: ('Upper East Side', 'Manhattan')\n",
      "**************************************\n",
      "Pickup: ('Manhattan Community Board 6', 'Manhattan')\n",
      "Dropoff: ('Manhattan Community Board 2', 'Manhattan')\n",
      "**************************************\n",
      "Pickup: ('Manhattan Community Board 6', 'Manhattan')\n",
      "Dropoff: ('Manhattan Community Board 3', 'Manhattan')\n",
      "**************************************\n",
      "Pickup: ('Manhattan Community Board 6', 'Manhattan')\n",
      "Dropoff: ('Manhattan Community Board 6', 'Manhattan')\n",
      "**************************************\n",
      "Pickup: ('Lenox Hill', 'Manhattan')\n",
      "Dropoff: ('Manhattan Community Board 1', 'Manhattan')\n",
      "**************************************\n",
      "Pickup: ('Manhattan Community Board 6', 'Manhattan')\n",
      "Dropoff: ('Manhattan Community Board 6', 'Manhattan')\n",
      "**************************************\n",
      "Pickup: ('Manhattan Community Board 2', 'Manhattan')\n",
      "Dropoff: ('Manhattan Community Board 5', 'Manhattan')\n",
      "**************************************\n",
      "Pickup: ('Manhattan Community Board 3', 'Manhattan')\n",
      "Dropoff: ('Chelsea', 'Manhattan')\n",
      "**************************************\n",
      "Pickup: ('Manhattan Community Board 10', 'Manhattan')\n",
      "Dropoff: ('Manhattan Community Board 6', 'Manhattan')\n",
      "**************************************\n",
      "Pickup: ('Cropsey Avenue', 'Brooklyn')\n",
      "Dropoff: ('Kings Highway', 'Brooklyn')\n",
      "**************************************\n",
      "Pickup: ('Upper West Side', 'Manhattan')\n",
      "Dropoff: ('Marine Terminal Road', 'Queens')\n",
      "**************************************\n",
      "Pickup: ('Manhattan Community Board 5', 'Manhattan')\n",
      "Dropoff: ('Manhattan Community Board 3', 'Manhattan')\n",
      "**************************************\n",
      "Pickup: ('Manhattan Community Board 5', 'Manhattan')\n",
      "Dropoff: ('Manhattan Community Board 3', 'Manhattan')\n",
      "**************************************\n",
      "Pickup: ('Manhattan Community Board 7', 'Manhattan')\n",
      "Dropoff: ('Manhattan Community Board 11', 'Manhattan')\n",
      "**************************************\n",
      "Pickup: ('Financial District', 'Manhattan')\n",
      "Dropoff: ('79th Street Transverse', 'Manhattan')\n",
      "**************************************\n",
      "Pickup: ('Manhattan Community Board 1', 'Manhattan')\n",
      "Dropoff: ('Manhattan Community Board 1', 'Manhattan')\n",
      "**************************************\n",
      "Pickup: ('Manhattan Community Board 11', 'Manhattan')\n",
      "Dropoff: ('Manhattan Community Board 5', 'Manhattan')\n",
      "**************************************\n",
      "19.85903000831604\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from location_finder import LocationFinder\n",
    "# Initialize the BoroughFinder with the path to your GeoJSON file\n",
    "\n",
    "finder = LocationFinder()\n",
    "\n",
    "\n",
    "# pickup_boroughs = {'Manhattan': 0, 'Queens': 0, 'Brooklyn': 0, 'Bronx': 0, 'Staten Island': 0}\n",
    "# dropoff_boroughs = {'Manhattan': 0, 'Queens': 0, 'Brooklyn': 0, 'Bronx': 0, 'Staten Island': 0}\n",
    "\n",
    "errors = 0\n",
    "counter = 0\n",
    "\n",
    "t1 = time.time()\n",
    "# Iterate over the rows of the DataFrame\n",
    "for index, row in uber_data.head(20).iterrows():\n",
    "    counter += 1\n",
    "    pickup_latitude = row['pickup_latitude']\n",
    "    pickup_longitude = row['pickup_longitude']\n",
    "    # pickup_location = reverse_geocode(pickup_latitude, pickup_longitude)\n",
    "    # pickup_location_list = location.split(', ')\n",
    "\n",
    "    pickup_loc = finder.find_location(pickup_longitude, pickup_latitude)\n",
    "\n",
    "    dropoff_latitude = row['dropoff_latitude']\n",
    "    dropoff_longitude = row['dropoff_longitude']\n",
    "    # dropoff_location = reverse_geocode(dropoff_latitude, dropoff_longitude)\n",
    "    # dropoff_location_list = location.split(', ')\n",
    "\n",
    "    dropoff_loc = finder.find_location(dropoff_longitude, dropoff_latitude)\n",
    "\n",
    "    try:\n",
    "        # pickup_boroughs[pickup_borough] += 1\n",
    "        # dropoff_boroughs[pickup_borough] += 1\n",
    "        print(f'Pickup: {pickup_loc}')\n",
    "        print(f'Dropoff: {dropoff_loc}')\n",
    "    except:\n",
    "        errors += 1\n",
    "\n",
    "    # print(location_list[-6])\n",
    "    # print(len(location_list))\n",
    "    # print(pickup_location_list[-6])\n",
    "    # print(dropoff_location_list[-6])\n",
    "    print('**************************************')\n",
    "t2 = time.time()\n",
    "print(t2-t1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pickup: ('Upper West Side', 'Manhattan')\n",
      "Dropoff: ('Upper East Side', 'Manhattan')\n",
      "Pickup: ('Lower East Side', 'Manhattan')\n",
      "Dropoff: ('Cobble Hill', 'Brooklyn')\n",
      "Pickup: ('Upper East Side', 'Manhattan')\n",
      "Dropoff: ('Chelsea', 'Manhattan')\n",
      "Pickup: ('East Village', 'Manhattan')\n",
      "Dropoff: ('Upper East Side', 'Manhattan')\n",
      "Pickup: ('Gramercy', 'Manhattan')\n",
      "Dropoff: ('SoHo', 'Manhattan')\n",
      "Pickup: ('Gramercy', 'Manhattan')\n",
      "Dropoff: ('East Village', 'Manhattan')\n",
      "Pickup: ('Murray Hill', 'Manhattan')\n",
      "Dropoff: ('Kips Bay', 'Manhattan')\n",
      "Pickup: ('Upper East Side', 'Manhattan')\n",
      "Dropoff: ('Financial District', 'Manhattan')\n",
      "Pickup: ('Midtown', 'Manhattan')\n",
      "Dropoff: ('Murray Hill', 'Manhattan')\n",
      "Pickup: ('East Village', 'Manhattan')\n",
      "Dropoff: ('Murray Hill', 'Manhattan')\n",
      "Pickup: ('East Village', 'Manhattan')\n",
      "Dropoff: ('Chelsea', 'Manhattan')\n",
      "Pickup: ('Harlem', 'Manhattan')\n",
      "Dropoff: ('Stuyvesant Town', 'Manhattan')\n",
      "Pickup: ('Bath Beach', 'Brooklyn')\n",
      "Dropoff: ('Sheepshead Bay', 'Brooklyn')\n",
      "Pickup: ('Upper West Side', 'Manhattan')\n",
      "Dropoff: ('LaGuardia Airport', 'Queens')\n",
      "Pickup: ('Midtown', 'Manhattan')\n",
      "Dropoff: ('East Village', 'Manhattan')\n",
      "Pickup: ('Flatiron District', 'Manhattan')\n",
      "Dropoff: ('East Village', 'Manhattan')\n",
      "Pickup: ('Upper West Side', 'Manhattan')\n",
      "Dropoff: ('East Harlem', 'Manhattan')\n",
      "Pickup: ('Battery Park City', 'Manhattan')\n",
      "Dropoff: ('Upper West Side', 'Manhattan')\n",
      "Pickup: ('Financial District', 'Manhattan')\n",
      "Dropoff: ('Financial District', 'Manhattan')\n",
      "Pickup: ('Harlem', 'Manhattan')\n",
      "Dropoff: ('Midtown', 'Manhattan')\n",
      "0.8888740539550781\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from borough_finder import BoroughFinder\n",
    "# Initialize the BoroughFinder with the path to your GeoJSON file\n",
    "geojson_path = 'nyc-neighborhoods-2.geojson'  # Adjust the path if necessary\n",
    "finder = BoroughFinder(geojson_path)\n",
    "\n",
    "\n",
    "# pickup_boroughs = {'Manhattan': 0, 'Queens': 0, 'Brooklyn': 0, 'Bronx': 0, 'Staten Island': 0}\n",
    "# dropoff_boroughs = {'Manhattan': 0, 'Queens': 0, 'Brooklyn': 0, 'Bronx': 0, 'Staten Island': 0}\n",
    "\n",
    "errors = 0\n",
    "counter = 0\n",
    "\n",
    "t1 = time.time()\n",
    "# Iterate over the rows of the DataFrame\n",
    "for index, row in uber_data.head(20).iterrows():\n",
    "    counter += 1\n",
    "    pickup_latitude = row['pickup_latitude']\n",
    "    pickup_longitude = row['pickup_longitude']\n",
    "    # pickup_location = reverse_geocode(pickup_latitude, pickup_longitude)\n",
    "    # pickup_location_list = location.split(', ')\n",
    "\n",
    "    pickup_loc = finder.find_location(pickup_longitude, pickup_latitude)\n",
    "\n",
    "    dropoff_latitude = row['dropoff_latitude']\n",
    "    dropoff_longitude = row['dropoff_longitude']\n",
    "    # dropoff_location = reverse_geocode(dropoff_latitude, dropoff_longitude)\n",
    "    # dropoff_location_list = location.split(', ')\n",
    "\n",
    "    dropoff_loc = finder.find_location(dropoff_longitude, dropoff_latitude)\n",
    "\n",
    "    # try:\n",
    "    #     pickup_boroughs[pickup_borough] += 1\n",
    "    #     dropoff_boroughs[pickup_borough] += 1\n",
    "    # except:\n",
    "    #     errors += 1\n",
    "    #     print(f'Error with pickup: {pickup_borough} and dropoff: {dropoff_borough}')\n",
    "    #     print(f'Current count: {errors} out of {counter}')\n",
    "    print(f'Pickup: {pickup_loc}')\n",
    "    print(f'Dropoff: {dropoff_loc}')\n",
    "\n",
    "    \n",
    "    # print(location_list[-6])\n",
    "    # print(len(location_list))\n",
    "    # print(pickup_location_list[-6])\n",
    "    # print(dropoff_location_list[-6])\n",
    "    # print('**************************************')\n",
    "t2 = time.time()\n",
    "print(t2-t1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Parallel Processing\n",
    "# import concurrent.futures\n",
    "\n",
    "# # Function to process each row of the DataFrame\n",
    "# def process_row(row):\n",
    "#     pickup_latitude = row['pickup_latitude']\n",
    "#     pickup_longitude = row['pickup_longitude']\n",
    "#     dropoff_latitude = row['dropoff_latitude']\n",
    "#     dropoff_longitude = row['dropoff_longitude']\n",
    "\n",
    "#     pickup_loc = finder.find_location(pickup_longitude, pickup_latitude)\n",
    "#     dropoff_loc = finder.find_location(dropoff_longitude, dropoff_latitude)\n",
    "\n",
    "#     return pickup_loc, dropoff_loc\n",
    "\n",
    "# # Use ThreadPoolExecutor to process rows in parallel\n",
    "# with concurrent.futures.ThreadPoolExecutor() as executor:\n",
    "#     # Submit tasks to the executor\n",
    "#     futures = {executor.submit(process_row, row): index for index, row in uber_data.head(20).iterrows()}\n",
    "    \n",
    "#     # Process the results as they complete\n",
    "#     for future in concurrent.futures.as_completed(futures):\n",
    "#         index = futures[future]\n",
    "#         try:\n",
    "#             pickup_loc, dropoff_loc = future.result()\n",
    "#             print(f'Pickup: {pickup_loc}')\n",
    "#             print(f'Dropoff: {dropoff_loc}')\n",
    "#         except Exception as e:\n",
    "#             errors += 1\n",
    "#             print(f\"Error processing row {index}: {e}\")\n",
    "#         finally:\n",
    "#             print('**************************************')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "geojson_path = 'nyc-neighborhoods-2.geojson'  # Adjust the path if necessary\n",
    "finder = BoroughFinder(geojson_path)\n",
    "\n",
    "t1 = time.time()\n",
    "uber_data['pickup_loc'] = uber_data.head(40).apply(lambda row: finder.find_location(row['pickup_longitude'], row['pickup_latitude']), axis=1)\n",
    "uber_data['dropoff_loc'] = uber_data.head(40).apply(lambda row: finder.find_location(row['dropoff_longitude'], row['dropoff_latitude']), axis=1)\n",
    "t2 = time.time()\n",
    "\n",
    "print(t2-t1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uber_data.head(40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "from shapely.geometry import Point\n",
    "\n",
    "# Step 1: Load borough boundaries\n",
    "# Assuming you have a GeoJSON file with the boundaries of NYC boroughs\n",
    "boroughs = gpd.read_file('nyc-neighborhoods.geojson')\n",
    "\n",
    "# Step 2: Convert latitude and longitude to a Shapely Point\n",
    "latitude = 40.824312  # Example latitude\n",
    "longitude = -73.926457  # Example longitude\n",
    "location_point = Point(longitude, latitude)\n",
    "\n",
    "# Step 3: Check which borough contains the point\n",
    "borough_name = None\n",
    "for _, borough in boroughs.iterrows():\n",
    "    if borough['geometry'].contains(location_point):\n",
    "        borough_name = borough['name']  # Assuming the borough name is in a column called 'borough'\n",
    "        break\n",
    "\n",
    "# Step 4: Output the result\n",
    "if borough_name:\n",
    "    print(f\"The location is in the borough: {borough_name}\")\n",
    "else:\n",
    "    print(\"The location is not in any recognized borough.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "from shapely.geometry import Point\n",
    "from shapely.validation import make_valid\n",
    "\n",
    "# Step 1: Load borough boundaries\n",
    "boroughs = gpd.read_file('nyc-neighborhoods-2.geojson')\n",
    "\n",
    "# Step 2: Validate and fix geometries\n",
    "def fix_geometry(geom):\n",
    "    if not geom.is_valid:\n",
    "        geom = make_valid(geom)  # Attempt to make the geometry valid\n",
    "    if not geom.is_valid:  # Further attempt to fix with buffer(0)\n",
    "        geom = geom.buffer(0)\n",
    "    return geom\n",
    "\n",
    "boroughs['geometry'] = boroughs['geometry'].apply(fix_geometry)\n",
    "\n",
    "# Check if there are still any invalid geometries\n",
    "invalid_geometries = boroughs[~boroughs['geometry'].is_valid]\n",
    "if not invalid_geometries.empty:\n",
    "    print(\"There are still invalid geometries:\")\n",
    "    print(invalid_geometries)\n",
    "\n",
    "# Step 3: Convert latitude and longitude to a Shapely Point\n",
    "latitude = 40.824312  # Example latitude\n",
    "longitude = -73.926457  # Example longitude\n",
    "location_point = Point(longitude, latitude)\n",
    "\n",
    "# Step 4: Check which borough contains the point using 'within'\n",
    "borough_name = None\n",
    "for _, borough in boroughs.iterrows():\n",
    "    if location_point.within(borough['geometry']):\n",
    "        borough_name = borough['borough']  # Assuming the borough name is in a column called 'name'\n",
    "        neighborhood_name = borough['neighborhood'] # Assuming the neighborhood name is in a column called 'neighborhood'\n",
    "        break\n",
    "\n",
    "# Step 5: Output the result\n",
    "if borough_name and neighborhood_name:\n",
    "    print(f\"The location is in the borough: {borough_name} and neighborhood: {neighborhood_name}\")\n",
    "else:\n",
    "    print(\"The location is not in any recognized borough.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before: (199494, 24)\n",
      "After: (195545, 24)\n"
     ]
    }
   ],
   "source": [
    "new_df = pd.read_csv('updated_uber_loc.csv')\n",
    "new_df.head()\n",
    "print(f'Before: {new_df.shape}')\n",
    "new_df = new_df[(new_df['pickup_latitude'] != 0) & (new_df['pickup_longitude'] != 0) & (new_df['dropoff_latitude'] != 0) & (new_df['dropoff_longitude'] != 0)]\n",
    "print(f'After: {new_df.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0           ('Upper West Side', 'Manhattan')\n",
       "1           ('Lower East Side', 'Manhattan')\n",
       "2           ('Upper East Side', 'Manhattan')\n",
       "3              ('East Village', 'Manhattan')\n",
       "4                  ('Gramercy', 'Manhattan')\n",
       "                         ...                \n",
       "199489      ('Upper West Side', 'Manhattan')\n",
       "199490    ('Greenwich Village', 'Manhattan')\n",
       "199491         ('West Village', 'Manhattan')\n",
       "199492     ('Theater District', 'Manhattan')\n",
       "199493              ('Midtown', 'Manhattan')\n",
       "Name: pickup_loc, Length: 195545, dtype: object"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Upper West Side\n",
      "Lower East Side\n",
      "Upper East Side\n",
      "East Village\n",
      "Gramercy\n",
      "Gramercy\n",
      "Murray Hill\n",
      "Upper East Side\n",
      "Midtown\n",
      "East Village\n",
      "East Village\n",
      "Harlem\n",
      "Bath Beach\n",
      "Upper West Side\n",
      "Midtown\n",
      "Flatiron District\n",
      "Upper West Side\n",
      "Battery Park City\n",
      "Financial District\n",
      "Harlem\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Public\\Documents\\Wondershare\\CreatorTemp\\ipykernel_14268\\1801064162.py:4: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  pickup_loc_str = row[uber_data.columns.get_loc('pickup_loc')]\n"
     ]
    }
   ],
   "source": [
    "import ast\n",
    "\n",
    "for index, row in uber_data.head(20).iterrows():\n",
    "    pickup_loc_str = row[uber_data.columns.get_loc('pickup_loc')]\n",
    "    pickup_loc_tuple = ast.literal_eval(pickup_loc_str)\n",
    "    print(pickup_loc_tuple[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "malformed node or string: nan",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[27], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mast\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# Convert the string representation of tuples to actual tuples and create new columns\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m uber_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpickup_neighborhood\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m uber_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpickup_loc\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m x: ast\u001b[38;5;241m.\u001b[39mliteral_eval(x)[\u001b[38;5;241m0\u001b[39m])\n\u001b[0;32m      5\u001b[0m uber_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpickup_borough\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m uber_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpickup_loc\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m x: ast\u001b[38;5;241m.\u001b[39mliteral_eval(x)[\u001b[38;5;241m1\u001b[39m])\n\u001b[0;32m      6\u001b[0m uber_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdropoff_neighborhood\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m uber_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdropoff_loc\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m x: ast\u001b[38;5;241m.\u001b[39mliteral_eval(x)[\u001b[38;5;241m0\u001b[39m])\n",
      "File \u001b[1;32mc:\\Users\\Bashar\\anaconda3\\Lib\\site-packages\\pandas\\core\\series.py:4924\u001b[0m, in \u001b[0;36mSeries.apply\u001b[1;34m(self, func, convert_dtype, args, by_row, **kwargs)\u001b[0m\n\u001b[0;32m   4789\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply\u001b[39m(\n\u001b[0;32m   4790\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   4791\u001b[0m     func: AggFuncType,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4796\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m   4797\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame \u001b[38;5;241m|\u001b[39m Series:\n\u001b[0;32m   4798\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   4799\u001b[0m \u001b[38;5;124;03m    Invoke function on values of Series.\u001b[39;00m\n\u001b[0;32m   4800\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4915\u001b[0m \u001b[38;5;124;03m    dtype: float64\u001b[39;00m\n\u001b[0;32m   4916\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m   4917\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m SeriesApply(\n\u001b[0;32m   4918\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   4919\u001b[0m         func,\n\u001b[0;32m   4920\u001b[0m         convert_dtype\u001b[38;5;241m=\u001b[39mconvert_dtype,\n\u001b[0;32m   4921\u001b[0m         by_row\u001b[38;5;241m=\u001b[39mby_row,\n\u001b[0;32m   4922\u001b[0m         args\u001b[38;5;241m=\u001b[39margs,\n\u001b[0;32m   4923\u001b[0m         kwargs\u001b[38;5;241m=\u001b[39mkwargs,\n\u001b[1;32m-> 4924\u001b[0m     )\u001b[38;5;241m.\u001b[39mapply()\n",
      "File \u001b[1;32mc:\\Users\\Bashar\\anaconda3\\Lib\\site-packages\\pandas\\core\\apply.py:1427\u001b[0m, in \u001b[0;36mSeriesApply.apply\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1424\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_compat()\n\u001b[0;32m   1426\u001b[0m \u001b[38;5;66;03m# self.func is Callable\u001b[39;00m\n\u001b[1;32m-> 1427\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_standard()\n",
      "File \u001b[1;32mc:\\Users\\Bashar\\anaconda3\\Lib\\site-packages\\pandas\\core\\apply.py:1507\u001b[0m, in \u001b[0;36mSeriesApply.apply_standard\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1501\u001b[0m \u001b[38;5;66;03m# row-wise access\u001b[39;00m\n\u001b[0;32m   1502\u001b[0m \u001b[38;5;66;03m# apply doesn't have a `na_action` keyword and for backward compat reasons\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m \u001b[38;5;66;03m# we need to give `na_action=\"ignore\"` for categorical data.\u001b[39;00m\n\u001b[0;32m   1504\u001b[0m \u001b[38;5;66;03m# TODO: remove the `na_action=\"ignore\"` when that default has been changed in\u001b[39;00m\n\u001b[0;32m   1505\u001b[0m \u001b[38;5;66;03m#  Categorical (GH51645).\u001b[39;00m\n\u001b[0;32m   1506\u001b[0m action \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(obj\u001b[38;5;241m.\u001b[39mdtype, CategoricalDtype) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1507\u001b[0m mapped \u001b[38;5;241m=\u001b[39m obj\u001b[38;5;241m.\u001b[39m_map_values(\n\u001b[0;32m   1508\u001b[0m     mapper\u001b[38;5;241m=\u001b[39mcurried, na_action\u001b[38;5;241m=\u001b[39maction, convert\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconvert_dtype\n\u001b[0;32m   1509\u001b[0m )\n\u001b[0;32m   1511\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(mapped) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(mapped[\u001b[38;5;241m0\u001b[39m], ABCSeries):\n\u001b[0;32m   1512\u001b[0m     \u001b[38;5;66;03m# GH#43986 Need to do list(mapped) in order to get treated as nested\u001b[39;00m\n\u001b[0;32m   1513\u001b[0m     \u001b[38;5;66;03m#  See also GH#25959 regarding EA support\u001b[39;00m\n\u001b[0;32m   1514\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m obj\u001b[38;5;241m.\u001b[39m_constructor_expanddim(\u001b[38;5;28mlist\u001b[39m(mapped), index\u001b[38;5;241m=\u001b[39mobj\u001b[38;5;241m.\u001b[39mindex)\n",
      "File \u001b[1;32mc:\\Users\\Bashar\\anaconda3\\Lib\\site-packages\\pandas\\core\\base.py:921\u001b[0m, in \u001b[0;36mIndexOpsMixin._map_values\u001b[1;34m(self, mapper, na_action, convert)\u001b[0m\n\u001b[0;32m    918\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(arr, ExtensionArray):\n\u001b[0;32m    919\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m arr\u001b[38;5;241m.\u001b[39mmap(mapper, na_action\u001b[38;5;241m=\u001b[39mna_action)\n\u001b[1;32m--> 921\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m algorithms\u001b[38;5;241m.\u001b[39mmap_array(arr, mapper, na_action\u001b[38;5;241m=\u001b[39mna_action, convert\u001b[38;5;241m=\u001b[39mconvert)\n",
      "File \u001b[1;32mc:\\Users\\Bashar\\anaconda3\\Lib\\site-packages\\pandas\\core\\algorithms.py:1743\u001b[0m, in \u001b[0;36mmap_array\u001b[1;34m(arr, mapper, na_action, convert)\u001b[0m\n\u001b[0;32m   1741\u001b[0m values \u001b[38;5;241m=\u001b[39m arr\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mobject\u001b[39m, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m na_action \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1743\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m lib\u001b[38;5;241m.\u001b[39mmap_infer(values, mapper, convert\u001b[38;5;241m=\u001b[39mconvert)\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1745\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m lib\u001b[38;5;241m.\u001b[39mmap_infer_mask(\n\u001b[0;32m   1746\u001b[0m         values, mapper, mask\u001b[38;5;241m=\u001b[39misna(values)\u001b[38;5;241m.\u001b[39mview(np\u001b[38;5;241m.\u001b[39muint8), convert\u001b[38;5;241m=\u001b[39mconvert\n\u001b[0;32m   1747\u001b[0m     )\n",
      "File \u001b[1;32mlib.pyx:2972\u001b[0m, in \u001b[0;36mpandas._libs.lib.map_infer\u001b[1;34m()\u001b[0m\n",
      "Cell \u001b[1;32mIn[27], line 4\u001b[0m, in \u001b[0;36m<lambda>\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mast\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# Convert the string representation of tuples to actual tuples and create new columns\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m uber_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpickup_neighborhood\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m uber_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpickup_loc\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m x: ast\u001b[38;5;241m.\u001b[39mliteral_eval(x)[\u001b[38;5;241m0\u001b[39m])\n\u001b[0;32m      5\u001b[0m uber_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpickup_borough\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m uber_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpickup_loc\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m x: ast\u001b[38;5;241m.\u001b[39mliteral_eval(x)[\u001b[38;5;241m1\u001b[39m])\n\u001b[0;32m      6\u001b[0m uber_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdropoff_neighborhood\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m uber_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdropoff_loc\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m x: ast\u001b[38;5;241m.\u001b[39mliteral_eval(x)[\u001b[38;5;241m0\u001b[39m])\n",
      "File \u001b[1;32mc:\\Users\\Bashar\\anaconda3\\Lib\\ast.py:112\u001b[0m, in \u001b[0;36mliteral_eval\u001b[1;34m(node_or_string)\u001b[0m\n\u001b[0;32m    110\u001b[0m                 \u001b[38;5;28;01mreturn\u001b[39;00m left \u001b[38;5;241m-\u001b[39m right\n\u001b[0;32m    111\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _convert_signed_num(node)\n\u001b[1;32m--> 112\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _convert(node_or_string)\n",
      "File \u001b[1;32mc:\\Users\\Bashar\\anaconda3\\Lib\\ast.py:111\u001b[0m, in \u001b[0;36mliteral_eval.<locals>._convert\u001b[1;34m(node)\u001b[0m\n\u001b[0;32m    109\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    110\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m left \u001b[38;5;241m-\u001b[39m right\n\u001b[1;32m--> 111\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _convert_signed_num(node)\n",
      "File \u001b[1;32mc:\\Users\\Bashar\\anaconda3\\Lib\\ast.py:85\u001b[0m, in \u001b[0;36mliteral_eval.<locals>._convert_signed_num\u001b[1;34m(node)\u001b[0m\n\u001b[0;32m     83\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     84\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;241m-\u001b[39m operand\n\u001b[1;32m---> 85\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _convert_num(node)\n",
      "File \u001b[1;32mc:\\Users\\Bashar\\anaconda3\\Lib\\ast.py:76\u001b[0m, in \u001b[0;36mliteral_eval.<locals>._convert_num\u001b[1;34m(node)\u001b[0m\n\u001b[0;32m     74\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_convert_num\u001b[39m(node):\n\u001b[0;32m     75\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(node, Constant) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(node\u001b[38;5;241m.\u001b[39mvalue) \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;28mint\u001b[39m, \u001b[38;5;28mfloat\u001b[39m, \u001b[38;5;28mcomplex\u001b[39m):\n\u001b[1;32m---> 76\u001b[0m         _raise_malformed_node(node)\n\u001b[0;32m     77\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m node\u001b[38;5;241m.\u001b[39mvalue\n",
      "File \u001b[1;32mc:\\Users\\Bashar\\anaconda3\\Lib\\ast.py:73\u001b[0m, in \u001b[0;36mliteral_eval.<locals>._raise_malformed_node\u001b[1;34m(node)\u001b[0m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m lno \u001b[38;5;241m:=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(node, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlineno\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m     72\u001b[0m     msg \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m on line \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlno\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m---> 73\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg \u001b[38;5;241m+\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnode\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mValueError\u001b[0m: malformed node or string: nan"
     ]
    }
   ],
   "source": [
    "import ast\n",
    "\n",
    "# Convert the string representation of tuples to actual tuples and create new columns\n",
    "uber_data['pickup_neighborhood'] = uber_data['pickup_loc'].apply(lambda x: ast.literal_eval(x)[0])\n",
    "uber_data['pickup_borough'] = uber_data['pickup_loc'].apply(lambda x: ast.literal_eval(x)[1])\n",
    "uber_data['dropoff_neighborhood'] = uber_data['dropoff_loc'].apply(lambda x: ast.literal_eval(x)[0])\n",
    "uber_data['dropoff_borough'] = uber_data['dropoff_loc'].apply(lambda x: ast.literal_eval(x)[1])\n",
    "\n",
    "# Delete the original columns\n",
    "uber_data.drop(columns=['pickup_loc', 'dropoff_loc'], inplace=True)\n",
    "\n",
    "# Display the first few rows to verify the changes\n",
    "print(uber_data.head())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
